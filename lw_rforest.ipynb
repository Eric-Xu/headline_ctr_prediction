{
 "metadata": {
  "name": "",
  "signature": "sha256:62cecc3c36fbe2e52e361c41c8f8222fd5d1040565d60ca58d7383595151847f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.metrics import r2_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv(\"datasets/livewire_hits2.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>title</th>\n",
        "      <th>url</th>\n",
        "      <th>pub_date</th>\n",
        "      <th>day_0</th>\n",
        "      <th>day_1</th>\n",
        "      <th>day_2</th>\n",
        "      <th>day_3</th>\n",
        "      <th>day_4</th>\n",
        "      <th>day_5</th>\n",
        "      <th>day_6</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> Ancient Crimean Gold In Legal Limbo After Russ...</td>\n",
        "      <td> http://talkingpointsmemo.com/livewire/crimean-...</td>\n",
        "      <td> 2014-03-26T18:28:25</td>\n",
        "      <td>  1332</td>\n",
        "      <td>  103</td>\n",
        "      <td>   0</td>\n",
        "      <td>   0</td>\n",
        "      <td>   0</td>\n",
        "      <td>   0</td>\n",
        "      <td>   0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> California Sec. Of State Candidate Arrested In...</td>\n",
        "      <td> http://talkingpointsmemo.com/livewire/leland-y...</td>\n",
        "      <td> 2014-03-26T18:29:17</td>\n",
        "      <td> 10743</td>\n",
        "      <td> 1483</td>\n",
        "      <td> 136</td>\n",
        "      <td>  68</td>\n",
        "      <td>  54</td>\n",
        "      <td>  38</td>\n",
        "      <td>  32</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> Planet Biden: Scientists Nickname New Dwarf Pl...</td>\n",
        "      <td> http://talkingpointsmemo.com/livewire/dwarf-pl...</td>\n",
        "      <td> 2014-03-26T18:58:47</td>\n",
        "      <td>  4907</td>\n",
        "      <td> 2039</td>\n",
        "      <td> 288</td>\n",
        "      <td> 137</td>\n",
        "      <td> 107</td>\n",
        "      <td>  87</td>\n",
        "      <td>  74</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> Mass. Guv Candidate Passes Kidney Stone During...</td>\n",
        "      <td> http://talkingpointsmemo.com/livewire/mass-guv...</td>\n",
        "      <td> 2014-03-26T19:29:00</td>\n",
        "      <td> 27494</td>\n",
        "      <td> 7345</td>\n",
        "      <td> 740</td>\n",
        "      <td> 396</td>\n",
        "      <td> 295</td>\n",
        "      <td> 213</td>\n",
        "      <td> 100</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Charlotte's Brand New Mayor Turns Out To Be A ...</td>\n",
        "      <td> http://talkingpointsmemo.com/livewire/patrick-...</td>\n",
        "      <td> 2014-03-26T19:44:39</td>\n",
        "      <td>  6747</td>\n",
        "      <td> 1580</td>\n",
        "      <td> 127</td>\n",
        "      <td>  54</td>\n",
        "      <td>  36</td>\n",
        "      <td>  27</td>\n",
        "      <td>  22</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "                                               title  \\\n",
        "0  Ancient Crimean Gold In Legal Limbo After Russ...   \n",
        "1  California Sec. Of State Candidate Arrested In...   \n",
        "2  Planet Biden: Scientists Nickname New Dwarf Pl...   \n",
        "3  Mass. Guv Candidate Passes Kidney Stone During...   \n",
        "4  Charlotte's Brand New Mayor Turns Out To Be A ...   \n",
        "\n",
        "                                                 url             pub_date  \\\n",
        "0  http://talkingpointsmemo.com/livewire/crimean-...  2014-03-26T18:28:25   \n",
        "1  http://talkingpointsmemo.com/livewire/leland-y...  2014-03-26T18:29:17   \n",
        "2  http://talkingpointsmemo.com/livewire/dwarf-pl...  2014-03-26T18:58:47   \n",
        "3  http://talkingpointsmemo.com/livewire/mass-guv...  2014-03-26T19:29:00   \n",
        "4  http://talkingpointsmemo.com/livewire/patrick-...  2014-03-26T19:44:39   \n",
        "\n",
        "   day_0  day_1  day_2  day_3  day_4  day_5  day_6  \n",
        "0   1332    103      0      0      0      0      0  \n",
        "1  10743   1483    136     68     54     38     32  \n",
        "2   4907   2039    288    137    107     87     74  \n",
        "3  27494   7345    740    396    295    213    100  \n",
        "4   6747   1580    127     54     36     27     22  "
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.qcut(df.day_0, 4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "       [4, 1628.75]\n",
        " (9440.25, 1069673]\n",
        "    (3955, 9440.25]\n",
        " (9440.25, 1069673]\n",
        "    (3955, 9440.25]\n",
        "    (1628.75, 3955]\n",
        "    (3955, 9440.25]\n",
        "    (3955, 9440.25]\n",
        "    (1628.75, 3955]\n",
        "    (3955, 9440.25]\n",
        "    (1628.75, 3955]\n",
        "    (3955, 9440.25]\n",
        "    (1628.75, 3955]\n",
        "...\n",
        "    (3955, 9440.25]\n",
        " (9440.25, 1069673]\n",
        " (9440.25, 1069673]\n",
        "       [4, 1628.75]\n",
        " (9440.25, 1069673]\n",
        "    (1628.75, 3955]\n",
        "    (3955, 9440.25]\n",
        "    (3955, 9440.25]\n",
        "    (3955, 9440.25]\n",
        "    (3955, 9440.25]\n",
        " (9440.25, 1069673]\n",
        " (9440.25, 1069673]\n",
        "       [4, 1628.75]\n",
        "Levels (4): Index(['[4, 1628.75]', '(1628.75, 3955]', '(3955, 9440.25]',\n",
        "                   '(9440.25, 1069673]'], dtype=object)\n",
        "Name: day_0, Length: 7812"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def quartile_grouping(views):\n",
      "  if views < 1629:\n",
      "    return 0\n",
      "  elif views >= 1629 and views < 3955:\n",
      "    return 1\n",
      "  elif views >= 3955 and views < 9440:\n",
      "    return 2\n",
      "  elif views > 9440:\n",
      "    return 3\n",
      "  else:\n",
      "    return np.nan\n",
      "\n",
      "df['day_0_qt_group'] = df.day_0.apply(lambda x: quartile_grouping(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.qcut(df.day_0, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "   (1322.2, 1984.9]\n",
        "  (7792.7, 11508.4]\n",
        "     (3955, 5511.6]\n",
        " (18355.6, 1069673]\n",
        "   (5511.6, 7792.7]\n",
        "   (1984.9, 2818.2]\n",
        "   (5511.6, 7792.7]\n",
        "     (3955, 5511.6]\n",
        "     (2818.2, 3955]\n",
        "     (3955, 5511.6]\n",
        "     (2818.2, 3955]\n",
        "     (3955, 5511.6]\n",
        "   (1984.9, 2818.2]\n",
        "...\n",
        "     (3955, 5511.6]\n",
        " (18355.6, 1069673]\n",
        " (11508.4, 18355.6]\n",
        "      (800, 1322.2]\n",
        " (11508.4, 18355.6]\n",
        "   (1984.9, 2818.2]\n",
        "  (7792.7, 11508.4]\n",
        "   (5511.6, 7792.7]\n",
        "     (3955, 5511.6]\n",
        "     (3955, 5511.6]\n",
        "  (7792.7, 11508.4]\n",
        " (11508.4, 18355.6]\n",
        "   (1322.2, 1984.9]\n",
        "Levels (10): Index(['[4, 800]', '(800, 1322.2]', '(1322.2, 1984.9]',\n",
        "                    '(1984.9, 2818.2]', '(2818.2, 3955]',\n",
        "                    '(3955, 5511.6]', '(5511.6, 7792.7]',\n",
        "                    '(7792.7, 11508.4]', '(11508.4, 18355.6]',\n",
        "                    '(18355.6, 1069673]'], dtype=object)\n",
        "Name: day_0, Length: 7812"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def decile_grouping(views): # automate this using pd.qcut()\n",
      "  if views < 800:\n",
      "    return 0\n",
      "  elif views >= 800 and views < 1323:\n",
      "    return 1\n",
      "  elif views >= 1323 and views < 1985:\n",
      "    return 2\n",
      "  elif views >= 1985 and views < 2820:\n",
      "    return 3\n",
      "  elif views >= 2820 and views < 3955:\n",
      "    return 4\n",
      "  elif views >= 3955 and views < 5512:\n",
      "    return 5\n",
      "  elif views >= 5512 and views < 7793:\n",
      "    return 6\n",
      "  elif views >= 7793 and views < 11519:\n",
      "    return 7\n",
      "  elif views >= 11519 and views < 18357:\n",
      "    return 8\n",
      "  elif views > 18357:\n",
      "    return 9\n",
      "  else:\n",
      "    return np.nan\n",
      "\n",
      "df['day_0_dc_group'] = df.day_0.apply(lambda x: decile_grouping(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 7812 entries, 0 to 7811\n",
        "Data columns (total 12 columns):\n",
        "title             7810 non-null object\n",
        "url               7812 non-null object\n",
        "pub_date          7810 non-null object\n",
        "day_0             7812 non-null int64\n",
        "day_1             7812 non-null int64\n",
        "day_2             7812 non-null int64\n",
        "day_3             7812 non-null int64\n",
        "day_4             7812 non-null int64\n",
        "day_5             7812 non-null int64\n",
        "day_6             7812 non-null int64\n",
        "day_0_qt_group    7811 non-null float64\n",
        "day_0_dc_group    7812 non-null int64\n",
        "dtypes: float64(1), int64(8), object(3)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = df.dropna()\n",
      "df.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 7810 entries, 0 to 7811\n",
        "Data columns (total 10 columns):\n",
        "title       7810 non-null object\n",
        "url         7810 non-null object\n",
        "pub_date    7810 non-null object\n",
        "day_0       7810 non-null int64\n",
        "day_1       7810 non-null int64\n",
        "day_2       7810 non-null int64\n",
        "day_3       7810 non-null int64\n",
        "day_4       7810 non-null int64\n",
        "day_5       7810 non-null int64\n",
        "day_6       7810 non-null int64\n",
        "dtypes: int64(7), object(3)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Calculate word count"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Y = df.day_0_dc_group # lower accuracy than day_0_qt_group across all models\n",
      "# Y = df.day_0_qt_group \n",
      "Y = df.day_0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# vectorizer = CountVectorizer(stop_words=\"english\", ngram_range=(1,2), lowercase=True) # (7810, 48830)\n",
      "vectorizer = CountVectorizer(stop_words=\"english\", ngram_range=(1,2), lowercase=True, max_features=600)\n",
      "X_count = vectorizer.fit_transform(df.title)\n",
      "temp_vec = vectorizer.fit(df.title)\n",
      "\n",
      "xcount_train, xcount_test, ycount_train, ycount_test = train_test_split(X_count, Y, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_count.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "(7810, 600)"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Baseline Predictions Using Count Vectors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_test_train_sets(X, Y):\n",
      "    return train_test_split(X, Y, test_size=0.33)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reg_clfs = {'LinearReg': LinearRegression(),\n",
      "            'RandomForest': RandomForestClassifier(max_depth=3),\n",
      "            'ExtraTrees': ExtraTreesClassifier(max_depth=3)}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_score(classifiers, X, Y):\n",
      "    x_train, x_test, y_train, y_test = create_test_train_sets(X, Y)\n",
      "    for name, clf in classifiers.items():\n",
      "        start = time.time()\n",
      "        clf.fit(x_train.toarray(), y_train)\n",
      "        score = clf.score(x_test.toarray(), y_test)\n",
      "#         score = np.mean((y_test - clf.predict(x_test.toarray()))**2)\n",
      "        time_elapsed = time.time() - start\n",
      "        print \"%s produced an accuracy score of %0.4f in %0.2f seconds\"% (name, score, time_elapsed)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_score(reg_clfs, X_count, df.day_0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LinearReg produced an accuracy score of -212917506760959856738304.0000 in 2.03 seconds\n",
        "ExtraTrees produced an accuracy score of 0.0000 in 1.04 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "RandomForest produced an accuracy score of 0.0000 in 1.03 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Random Forest:\"\n",
      "ct_rf_clf = RandomForestClassifier(max_depth=3).fit(xcount_train.toarray(), ycount_train) # mse 160,187,521.363\n",
      "# ct_rf_clf = RandomForestClassifier(max_depth=10).fit(xcount_train.toarray(), ycount_train) # mse 177,398,026.019\n",
      "count_accuracy_report(ct_rf_clf)\n",
      "\n",
      "print cross_val_score(ct_rf_clf, xcount_train.toarray(), ycount_train)\n",
      "\n",
      "r2 = r2_score(ycount_test, ct_rf_clf.predict(xcount_test.toarray()))\n",
      "print r2\n",
      "mse = np.mean((ycount_test - ct_rf_clf.predict(xcount_test.toarray()))**2)\n",
      "print mse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Random Forest:\n",
        "Accuracy: 0.00%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.92%\n",
        "[ 0.00021119  0.00216685  0.00502513]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-0.40458665024"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "170005368.12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"ExtraTrees:\"\n",
      "ct_rf_clf = ExtraTreesClassifier(max_depth=3).fit(xcount_train.toarray(), ycount_train) # mse 160,187,521.363\n",
      "\n",
      "r2 = r2_score(ycount_test, ct_rf_clf.predict(xcount_test.toarray()))\n",
      "print r2\n",
      "mse = np.mean((ycount_test - ct_rf_clf.predict(xcount_test.toarray()))**2)\n",
      "print mse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ExtraTrees:\n",
        "-0.352959988345"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "163756690.148"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"GradientBoost:\"\n",
      "ct_rf_clf = GradientBoostingClassifier(max_depth=3).fit(xcount_train.toarray(), ycount_train) # mse 160,187,521.363\n",
      "\n",
      "r2 = r2_score(ycount_test, ct_rf_clf.predict(xcount_test.toarray()))\n",
      "print r2\n",
      "mse = np.mean((ycount_test - ct_rf_clf.predict(xcount_test.toarray()))**2)\n",
      "print mse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "GradientBoost:\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-25-25365c0c1cf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"GradientBoost:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mct_rf_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxcount_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mycount_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# mse 160,187,521.363\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mycount_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct_rf_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxcount_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mr2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, monitor)\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_score_to_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, monitor)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, random_state,\n\u001b[0;32m--> 783\u001b[0;31m                                     begin_at_stage, monitor)\n\u001b[0m\u001b[1;32m    784\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, random_state, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_mask,\n\u001b[0;32m--> 834\u001b[0;31m                                      criterion, splitter, random_state)\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_mask, criterion, splitter, random_state)\u001b[0m\n\u001b[1;32m    552\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_y\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;31m# induce regression tree on residuals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mnegative_gradient\u001b[0;34m(self, y, pred, k)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;34m\"\"\"Compute negative gradient for the ``k``-th class. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         return y - np.nan_to_num(np.exp(pred[:, k] -\n\u001b[0;32m--> 430\u001b[0;31m                                         logsumexp(pred, axis=1)))\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/extmath.pyc\u001b[0m in \u001b[0;36mlogsumexp\u001b[0;34m(arr, axis)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;31m# the less errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Linear Regression:\"\n",
      "ct_lr_clf = LinearRegression().fit(xcount_train.toarray(), ycount_train)\n",
      "\n",
      "r2 = r2_score(ycount_test, ct_lr_clf.predict(xcount_test.toarray()))\n",
      "print r2\n",
      "mse = np.mean((ycount_test - ct_lr_clf.predict(xcount_test.toarray()))**2)\n",
      "print mse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Linear Regression:\n",
        "-0.15812764526"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "140174987.872\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Calculate Term Frequency - Inverse Document Frequency (TF-IDF) "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf_transformer = TfidfTransformer().fit(X_count)\n",
      "X_tfidf = tfidf_transformer.transform(X_count)\n",
      "\n",
      "xtfidf_train, xtfidf_test, ytfidf_train, ytfidf_test = train_test_split(X_tfidf, Y, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def count_accuracy_report(_clf):\n",
      "    training_accuracy = _clf.score(xcount_train.toarray(), ycount_train)\n",
      "    test_accuracy = _clf.score(xcount_test.toarray(), ycount_test)\n",
      "    print \"Accuracy: %0.2f%%\" % (100 * test_accuracy)\n",
      "    print \"Accuracy on training data: %0.2f%%\" % (100 * training_accuracy)\n",
      "\n",
      "def tfidf_accuracy_report(_clf):\n",
      "    training_accuracy = _clf.score(xtfidf_train.toarray(), ytfidf_train)\n",
      "    test_accuracy = _clf.score(xtfidf_test.toarray(), ytfidf_test)\n",
      "    print \"Accuracy: %0.2f%%\" % (100 * test_accuracy)\n",
      "    print \"Accuracy on training data: %0.2f%%\" % (100 * training_accuracy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Random Forest tfidf:\"\n",
      "tf_rf_clf = RandomForestClassifier(max_depth=3).fit(xtfidf_train.toarray(), ytfidf_train)\n",
      "\n",
      "r2 = r2_score(ytfidf_test, tf_rf_clf.predict(xtfidf_test.toarray()))\n",
      "print r2\n",
      "mse = np.mean((ytfidf_test - tf_rf_clf.predict(xtfidf_test.toarray()))**2)\n",
      "print mse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Random Forest tfidf:\n",
        "-0.417036461628"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "171512241.881"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Predict pageviews with CountVectorizer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def AnalyzeHeadline(test_headline, clf):\n",
      "    print \"\\\"\"  + test_headline + \"\\\" is judged by classifier to be...\"\n",
      "    test_headline = temp_vec.transform([test_headline])\n",
      "    return(clf.predict(test_headline.toarray())[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 182
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ct_rf_clf = RandomForestClassifier(max_depth=3).fit(xcount_train.toarray(), ycount_train)\n",
      "AnalyzeHeadline(\"Police Group: Punish STL Rams Players for \u2018Hands Up\u2019 Gesture\", ct_rf_clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"Police Group: Punish STL Rams Players for \u2018Hands Up\u2019 Gesture\" is judged by classifier to be...\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 200,
       "text": [
        "407"
       ]
      }
     ],
     "prompt_number": 200
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Predict pageviews with TF-IDF"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tf_rf_clf = RandomForestClassifier(max_depth=3).fit(xtfidf_train.toarray(), ytfidf_train)\n",
      "AnalyzeHeadline(\"Police Group: Punish STL Rams Players for \u2018Hands Up\u2019 Gesture\", tf_rf_clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"Police Group: Punish STL Rams Players for \u2018Hands Up\u2019 Gesture\" is judged by classifier to be...\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 206,
       "text": [
        "407"
       ]
      }
     ],
     "prompt_number": 206
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Q: Run the previous cell several times. Why does the predicted page views change?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Try a Linear Regression Model for Comparison"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}