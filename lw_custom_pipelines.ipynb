{
 "metadata": {
  "name": "",
  "signature": "sha256:1fc6501d0e0f82f707335d4e3030cf4683358d4f1a09b4978f4ae2125bc9f763"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.pipeline import Pipeline, FeatureUnion\n",
      "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
      "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.cross_validation import train_test_split, cross_val_score, KFold\n",
      "from sklearn.metrics import r2_score, explained_variance_score, accuracy_score, confusion_matrix\n",
      "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.decomposition import PCA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Let's Start Off With the Sklearn Pipeline Tutorial"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import fetch_20newsgroups\n",
      "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
      "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print type(twenty_train)\n",
      "print twenty_train.target_names\n",
      "print type(twenty_train.data)\n",
      "print type(twenty_train.target)\n",
      "print twenty_train.target.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'sklearn.datasets.base.Bunch'>\n",
        "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n",
        "<type 'list'>\n",
        "<type 'numpy.ndarray'>\n",
        "(2257,)\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print twenty_train.data[:1] # type list\n",
      "print twenty_train.target[:1] # type ndarray"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'From: sd345@city.ac.uk (Michael Collier)\\nSubject: Converting images to HP LaserJet III?\\nNntp-Posting-Host: hampton\\nOrganization: The City University\\nLines: 14\\n\\nDoes anyone know of a good way (standard PC application/PD utility) to\\nconvert tif/img/tga files into LaserJet III format.  We would also like to\\ndo the same, converting to HPGL (HP plotter) files.\\n\\nPlease email any response.\\n\\nIs this the correct group?\\n\\nThanks in advance.  Michael.\\n-- \\nMichael Collier (Programmer)                 The Computer Unit,\\nEmail: M.P.Collier@uk.ac.city                The City University,\\nTel: 071 477-8000 x3769                      London,\\nFax: 071 477-8565                            EC1V 0HB.\\n']\n",
        "[1]\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mnb_pl = Pipeline([\n",
      "    ('vect', CountVectorizer()),\n",
      "    ('tfidf', TfidfTransformer()),\n",
      "    ('clf', MultinomialNB())\n",
      "])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mnb_pl = mnb_pl.fit(twenty_train.data, twenty_train.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
      "docs_test = twenty_test.data\n",
      "print type(docs_test)\n",
      "print len(docs_test)\n",
      "print docs_test[:1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<type 'list'>\n",
        "1502\n",
        "[u\"From: brian@ucsd.edu (Brian Kantor)\\nSubject: Re: HELP for Kidney Stones ..............\\nOrganization: The Avant-Garde of the Now, Ltd.\\nLines: 12\\nNNTP-Posting-Host: ucsd.edu\\n\\nAs I recall from my bout with kidney stones, there isn't any\\nmedication that can do anything about them except relieve the pain.\\n\\nEither they pass, or they have to be broken up with sound, or they have\\nto be extracted surgically.\\n\\nWhen I was in, the X-ray tech happened to mention that she'd had kidney\\nstones and children, and the childbirth hurt less.\\n\\nDemerol worked, although I nearly got arrested on my way home when I barfed\\nall over the police car parked just outside the ER.\\n\\t- Brian\\n\"]\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predicted = mnb_pl.predict(docs_test)\n",
      "np.mean(predicted == twenty_test.target) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "0.83488681757656458"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Now Let's Use Our Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lw_df = pd.read_csv(\"datasets/livewire_log_cumviews.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lw_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>title</th>\n",
        "      <th>views</th>\n",
        "      <th>log_views</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> Ancient Crimean Gold In Legal Limbo After Russ...</td>\n",
        "      <td>  1435</td>\n",
        "      <td>  7.268920</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> California Sec. Of State Candidate Arrested In...</td>\n",
        "      <td> 12418</td>\n",
        "      <td>  9.426902</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> Planet Biden: Scientists Nickname New Dwarf Pl...</td>\n",
        "      <td>  7351</td>\n",
        "      <td>  8.902592</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> Mass. Guv Candidate Passes Kidney Stone During...</td>\n",
        "      <td> 35843</td>\n",
        "      <td> 10.486904</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Charlotte's Brand New Mayor Turns Out To Be A ...</td>\n",
        "      <td>  8466</td>\n",
        "      <td>  9.043813</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "                                               title  views  log_views\n",
        "0  Ancient Crimean Gold In Legal Limbo After Russ...   1435   7.268920\n",
        "1  California Sec. Of State Candidate Arrested In...  12418   9.426902\n",
        "2  Planet Biden: Scientists Nickname New Dwarf Pl...   7351   8.902592\n",
        "3  Mass. Guv Candidate Passes Kidney Stone During...  35843  10.486904\n",
        "4  Charlotte's Brand New Mayor Turns Out To Be A ...   8466   9.043813"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = lw_df.title.values\n",
      "Y = lw_df.log_views\n",
      "print X.shape\n",
      "print Y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(7810,)\n",
        "(7810,)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
      "print x_train.shape\n",
      "print x_test.shape\n",
      "print y_train.shape\n",
      "print y_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(5232,)\n",
        "(2578,)\n",
        "(5232,)\n",
        "(2578,)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lw_pl = Pipeline([\n",
      "    ('vect', CountVectorizer()),\n",
      "    ('tfidf', TfidfTransformer()),\n",
      "    ('clf', LinearRegression())\n",
      "])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lw_pl = lw_pl.fit(x_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = lw_pl.predict(x_test)\n",
      "r2 = r2_score(y_test, predictions)\n",
      "ev = explained_variance_score(y_test, predictions)\n",
      "rmse = np.sqrt(np.mean((predictions - y_test)**2))\n",
      "print \"r2\", r2\n",
      "print \"ev\", ev\n",
      "print \"rmse\", rmse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "r2 -1.70068745489\n",
        "ev -1.70041763055\n",
        "rmse 2.13316688019\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "page_views = np.exp(lw_pl.predict(x_test[1]))\n",
      "print x_test[1]\n",
      "print \"predicted: %0.2f\" %(page_views[0])\n",
      "print \"actual: %0.2f\" %(np.exp(y_test[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NIH Official: 'Breach Of Protocol' Led To Health Worker Contracting Ebola\n",
        "predicted: 4948.64\n",
        "actual: 4018.00\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Custom Pipeline Transformer Tutorial"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Source:\n",
      "\n",
      "http://nbviewer.ipython.org/github/rasbt/pattern_classification/blob/master/machine_learning/scikit-learn/scikit-pipeline.ipynb\n",
      "http://stackoverflow.com/questions/25250654/how-can-i-use-a-custom-feature-selection-function-in-scikit-learns-pipeline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris_df = pd.read_csv(\"datasets/iris.csv\", header=None, sep=\",\")\n",
      "iris_df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
      "iris_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 5.1</td>\n",
        "      <td> 3.5</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 4.9</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 4.7</td>\n",
        "      <td> 3.2</td>\n",
        "      <td> 1.3</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 4.6</td>\n",
        "      <td> 3.1</td>\n",
        "      <td> 1.5</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 5.0</td>\n",
        "      <td> 3.6</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "     0    1    2    3            4\n",
        "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
        "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
        "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
        "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
        "4  5.0  3.6  1.4  0.2  Iris-setosa"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_dict = {i:label for i,label in zip(\n",
      "            range(4),\n",
      "              ('sepal length in cm', \n",
      "              'sepal width in cm', \n",
      "              'petal length in cm', \n",
      "              'petal width in cm', ))}\n",
      "feature_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "{0: 'sepal length in cm',\n",
        " 1: 'sepal width in cm',\n",
        " 2: 'petal length in cm',\n",
        " 3: 'petal width in cm'}"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = iris_df[[0,1,2,3]].values \n",
      "y = iris_df[4].values\n",
      "print X.shape\n",
      "print y.shape\n",
      "\n",
      "enc = LabelEncoder()\n",
      "label_encoder = enc.fit(y)\n",
      "y = label_encoder.transform(y) + 1\n",
      "\n",
      "label_dict = {1: 'Setosa', 2: 'Versicolor', 3:'Virginica'}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(150, 4)\n",
        "(150,)\n"
       ]
      }
     ],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=12345)\n",
      "print type (X_train)\n",
      "print type (y_train)\n",
      "print X_train.shape\n",
      "print y_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<type 'numpy.ndarray'>\n",
        "<type 'numpy.ndarray'>\n",
        "(90, 4)\n",
        "(90,)\n"
       ]
      }
     ],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class ColumnSelector:\n",
      "    \"\"\" A feature selector for scikit-learn's Pipeline class that returns\n",
      "        specified columns as a numpy nested array from a nested numpy array.\n",
      "    \"\"\"\n",
      "    def __init__(self, cols):\n",
      "        self.cols = cols\n",
      "        \n",
      "    def transform(self, X, y=None):\n",
      "        if type(self.cols) == tuple:\n",
      "            return X[:, self.cols]\n",
      "        else:\n",
      "            return X[:, [self.cols]]\n",
      "\n",
      "    def fit(self, X, y=None):\n",
      "        return self"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.array([[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]])\n",
      "x[:,[(0)]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 184,
       "text": [
        "array([[0],\n",
        "       [2],\n",
        "       [4],\n",
        "       [6],\n",
        "       [8]])"
       ]
      }
     ],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# http://stackoverflow.com/questions/21165751/what-does-a-colon-and-comma-stand-in-a-python-list\n",
      "\n",
      "x = np.array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "print x[:]\n",
      "print x[:, (1,4,7)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0 1 2 3 4 5 6 7 8 9]]\n",
        "[[1 4 7]]\n"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris_df.head(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 5.1</td>\n",
        "      <td> 3.5</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 4.9</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 206,
       "text": [
        "     0    1    2    3            4\n",
        "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
        "1  4.9  3.0  1.4  0.2  Iris-setosa"
       ]
      }
     ],
     "prompt_number": 206
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cs = ColumnSelector(cols=(0,1))\n",
      "selected = cs.transform(iris_df.values)\n",
      "selected[:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 205,
       "text": [
        "array([[5.1, 3.5],\n",
        "       [4.9, 3.0]], dtype=object)"
       ]
      }
     ],
     "prompt_number": 205
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class ArrayUpDimension:\n",
      "    \"\"\" A feature selector for scikit-learn's Pipeline class that converts\n",
      "        a nested numpy array into an unnested numpy array.\n",
      "    \"\"\"\n",
      "    def transform(self, X):\n",
      "        return X.reshape(X.shape[0] * X.shape[1])\n",
      "\n",
      "    def fit(self, *_):\n",
      "        return self"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.array([[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]])\n",
      "# x.reshape((x.shape[0], 1))\n",
      "x.reshape(x.shape[0]*x.shape[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 204,
       "text": [
        "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
       ]
      }
     ],
     "prompt_number": 204
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ss = StandardScaler()\n",
      "scaled = ss.fit_transform(iris_df[[0,1,2,3]].values)\n",
      "scaled[:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 208,
       "text": [
        "array([[-0.90068117,  1.03205722, -1.3412724 , -1.31297673],\n",
        "       [-1.14301691, -0.1249576 , -1.3412724 , -1.31297673]])"
       ]
      }
     ],
     "prompt_number": 208
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aud = ArrayUpDimension()\n",
      "upped = aud.transform(scaled)\n",
      "upped[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 215,
       "text": [
        "array([-0.90068117,  1.03205722, -1.3412724 , -1.31297673, -1.14301691])"
       ]
      }
     ],
     "prompt_number": 215
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Let's Put Things Together"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_all = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler()),           \n",
      "    ('classifier', GaussianNB())   \n",
      "    ])\n",
      "\n",
      "clf_petal = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler()), # returns a nested numpy array\n",
      "    ('reduce_dim', ColumnSelector(cols=(2,3))), # returns a nested numpy array\n",
      "    ('classifier', GaussianNB())   \n",
      "    ]) \n",
      "\n",
      "clf_pca = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler()),    \n",
      "    ('reduce_dim', PCA(n_components=2)),\n",
      "    ('classifier', GaussianNB())   \n",
      "    ])\n",
      "\n",
      "clf_lda = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler()), \n",
      "    ('reduce_dim', LDA(n_components=2)),\n",
      "    ('classifier', GaussianNB())   \n",
      "    ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 216
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = KFold(n=X_train.shape[0],  # total number of samples\n",
      "           n_folds=4,           # number of folds the dataset is divided into\n",
      "           random_state=12345)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 217
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_score(clf_lda, X_train, y_train, cv=cv, scoring='accuracy')\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 1.          0.95652174  0.90909091  1.        ]\n"
       ]
      }
     ],
     "prompt_number": 218
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = [ cross_val_score(clf, X_train, y_train, cv=cv, scoring='accuracy')\n",
      "            for clf in [clf_all, clf_petal, clf_pca, clf_lda]\n",
      "         ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 219
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for score,label in zip(scores, \n",
      "                       ['all attributes', \n",
      "                        'Petal dimensions (column 3 & 4)',\n",
      "                        'PCA dim. red. (n=2)', \n",
      "                        'LDA dim. red. (n=2)', \n",
      "                        ]\n",
      "                       ):\n",
      "    print(\"Accuracy: {:.2%} (+/- {:.2%}), {:}\".format(score.mean(), score.std(), label))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy: 95.50% (+/- 3.22%), all attributes\n",
        "Accuracy: 94.42% (+/- 3.68%), Petal dimensions (column 3 & 4)\n",
        "Accuracy: 85.42% (+/- 8.20%), PCA dim. red. (n=2)\n",
        "Accuracy: 96.64% (+/- 3.75%), LDA dim. red. (n=2)\n"
       ]
      }
     ],
     "prompt_number": 220
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_lda.fit(X_train, y_train)\n",
      "pred_test = clf_lda.predict(X_test)\n",
      "\n",
      "print('Prediction accuracy for the test dataset')\n",
      "print('{:.2%}'.format(accuracy_score(y_test, pred_test)))\n",
      "\n",
      "print('\\nConfusion Matrix of the Naive Bayes classifier')\n",
      "print(confusion_matrix(y_test, clf_lda.predict(X_test)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Prediction accuracy for the test dataset\n",
        "100.00%\n",
        "\n",
        "Confusion Matrix of the Naive Bayes classifier\n",
        "[[21  0  0]\n",
        " [ 0 22  0]\n",
        " [ 0  0 17]]\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Apply ColumnSelector to Livewire Dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lw_df.head(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>title</th>\n",
        "      <th>views</th>\n",
        "      <th>log_views</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> Ancient Crimean Gold In Legal Limbo After Russ...</td>\n",
        "      <td>  1435</td>\n",
        "      <td> 7.268920</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> California Sec. Of State Candidate Arrested In...</td>\n",
        "      <td> 12418</td>\n",
        "      <td> 9.426902</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> Planet Biden: Scientists Nickname New Dwarf Pl...</td>\n",
        "      <td>  7351</td>\n",
        "      <td> 8.902592</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "                                               title  views  log_views\n",
        "0  Ancient Crimean Gold In Legal Limbo After Russ...   1435   7.268920\n",
        "1  California Sec. Of State Candidate Arrested In...  12418   9.426902\n",
        "2  Planet Biden: Scientists Nickname New Dwarf Pl...   7351   8.902592"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lw_cus_pl = Pipeline([\n",
      "    ('reduce_dim', ColumnSelector(cols=(0))), # returns a nested numpy array\n",
      "    ('up_dim', ArrayUpDimension()), # returns an unnested numpy array\n",
      "    ('vect', CountVectorizer()),\n",
      "    ('tfidf', TfidfTransformer()),\n",
      "    ('clf', LinearRegression())\n",
      "])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = lw_df.values \n",
      "y = lw_df[\"log_views\"].values\n",
      "print type(X)\n",
      "print type(y)\n",
      "print X.shape\n",
      "print y.shape\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=12345)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<type 'numpy.ndarray'>\n",
        "<type 'numpy.ndarray'>\n",
        "(7810, 3)\n",
        "(7810,)\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lw_cus_pl = lw_cus_pl.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = lw_cus_pl.predict(X_test)\n",
      "r2 = r2_score(y_test, predictions)\n",
      "ev = explained_variance_score(y_test, predictions)\n",
      "rmse = np.sqrt(np.mean((predictions - y_test)**2))\n",
      "print \"r2\", r2\n",
      "print \"ev\", ev\n",
      "print \"rmse\", rmse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "r2 -1.27985694146\n",
        "ev -1.27982379062\n",
        "rmse 1.94618664107\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Using Feature Unions for Parallel Processes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class BleepCountTransformer:\n",
      "    def count_bleeps(self, X):\n",
      "        return X.count(\"*\")\n",
      "    \n",
      "    def transform(self, X, **transform_params):\n",
      "        vecfunc = np.vectorize(self.count_bleeps)\n",
      "        return vecfunc(X).astype(float)\n",
      "    \n",
      "    def fit(self, X, *_):\n",
      "        return self"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = lw_df[[\"title\"]].values\n",
      "\n",
      "def count_bleeps(data):\n",
      "    return data.count(\"*\")\n",
      "    \n",
      "bf = np.vectorize(count_bleeps)\n",
      "bleeps = bf(t).astype(float)\n",
      "print t[:2]\n",
      "print bleeps[:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[\"Ancient Crimean Gold In Legal Limbo After Russia's Invasion\"]\n",
        " [ 'California Sec. Of State Candidate Arrested In Connection With Massive FBI Raid']]\n",
        "[[ 0.]\n",
        " [ 0.]]\n"
       ]
      }
     ],
     "prompt_number": 230
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = lw_df[[\"title\"]].values\n",
      "bc = BleepCountTransformer()\n",
      "results = bc.transform(t)\n",
      "print results[:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.]\n",
        " [ 0.]]\n"
       ]
      }
     ],
     "prompt_number": 231
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# lw_fu_pl = Pipeline([ # passes\n",
      "#     ('extract_titles', ColumnSelector(cols=(0))),\n",
      "#     ('up_dim', ArrayUpDimension()),\n",
      "#     ('counts', CountVectorizer()),\n",
      "#     ('tf_idf', TfidfTransformer()),\n",
      "#     ('classifier', LinearRegression())\n",
      "# ])\n",
      "\n",
      "# lw_fu_pl = Pipeline([ # passes\n",
      "#     ('extract_titles', ColumnSelector(cols=(0))),\n",
      "#     ('bleeps', BleepCountTransformer()),\n",
      "#     ('classifier', LinearRegression())\n",
      "# ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "summary_tfidf_featurizer = Pipeline([\n",
      "  ('extract_titles', ColumnSelector(cols=(0))),\n",
      "  ('up_dim', ArrayUpDimension()),\n",
      "  ('counts', CountVectorizer()),\n",
      "  ('tf_idf', TfidfTransformer())\n",
      "])\n",
      "\n",
      "bleep_featurizer = Pipeline([\n",
      "  ('extract_titles', ColumnSelector(cols=(0))),\n",
      "  ('bleeps', BleepCountTransformer())\n",
      "])\n",
      "\n",
      "features = FeatureUnion([\n",
      "  ('bleep_featurizer', bleep_featurizer),\n",
      "  ('summary_tfidf', summary_tfidf_featurizer)\n",
      "])\n",
      "\n",
      "predictor = LinearRegression()\n",
      "\n",
      "pipeline = Pipeline([\n",
      "  ('feature_union', features),\n",
      "  ('predictor', predictor)\n",
      "])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = lw_df.values\n",
      "Y = lw_df.log_views\n",
      "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline = pipeline.fit(x_train, y_train)\n",
      "predictions = pipeline.predict(x_test)\n",
      "\n",
      "r2 = r2_score(y_test, predictions)\n",
      "ev = explained_variance_score(y_test, predictions)\n",
      "rmse = np.sqrt(np.mean((predictions - y_test)**2))\n",
      "print \"r2\", r2\n",
      "print \"ev\", ev\n",
      "print \"rmse\", rmse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "r2 -1.67909095511\n",
        "ev -1.67891815215\n",
        "rmse 2.12462064735\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Todo: Stacking Models Using Feature Unions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline = Pipeline([\n",
      "    ('features', FeatureUnion([\n",
      "        ('continuous', Pipeline([\n",
      "            ('extract', ColumnExtractor(CONTINUOUS_FIELDS)),\n",
      "            ('scale', Normalizer())\n",
      "        ])),\n",
      "        ('factors', Pipeline([\n",
      "            ('extract', ColumnExtractor(FACTOR_FIELDS)),\n",
      "            ('one_hot', OneHotEncoder(n_values=5)),\n",
      "            ('to_dense', DenseTransformer())\n",
      "        ])),\n",
      "        ('weekday', Pipeline([\n",
      "            ('extract', DayOfWeekTransformer()),\n",
      "            ('one_hot', OneHotEncoder()),\n",
      "            ('to_dense', DenseTransformer())\n",
      "        ])),\n",
      "        ('hour_of_day', HourOfDayTransformer()),\n",
      "        ('month', Pipeline([\n",
      "            ('extract', ColumnExtractor(['datetime'])),\n",
      "            ('to_month', DateTransformer()),\n",
      "            ('one_hot', OneHotEncoder()),\n",
      "            ('to_dense', DenseTransformer())\n",
      "        ])),\n",
      "        ('growth', Pipeline([\n",
      "            ('datetime', ColumnExtractor(['datetime'])),\n",
      "            ('to_numeric', MatrixConversion(int)),\n",
      "            ('regression', ModelTransformer(LinearRegression()))\n",
      "        ]))\n",
      "    ])),\n",
      "    ('estimators', FeatureUnion([\n",
      "        ('knn', ModelTransformer(KNeighborsRegressor(n_neighbors=5))),\n",
      "        ('gbr', ModelTransformer(GradientBoostingRegressor())),\n",
      "        ('dtr', ModelTransformer(DecisionTreeRegressor())),\n",
      "        ('etr', ModelTransformer(ExtraTreesRegressor())),\n",
      "        ('rfr', ModelTransformer(RandomForestRegressor())),\n",
      "        ('par', ModelTransformer(PassiveAggressiveRegressor())),\n",
      "        ('en', ModelTransformer(ElasticNet())),\n",
      "        ('cluster', ModelTransformer(KMeans(n_clusters=2)))\n",
      "    ])),\n",
      "    ('estimator', KNeighborsRegressor())\n",
      "])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}