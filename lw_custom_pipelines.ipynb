{
 "metadata": {
  "name": "",
  "signature": "sha256:377cc059e5ddc1e2936e7e60df205e88a32249aaf0bbba07e89303df0c28a467"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.pipeline import Pipeline, FeatureUnion\n",
      "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
      "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.cross_validation import train_test_split, cross_val_score, KFold\n",
      "from sklearn.metrics import r2_score, explained_variance_score, accuracy_score, confusion_matrix\n",
      "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.decomposition import PCA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Let's Start Off With the Sklearn Pipeline Tutorial"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import fetch_20newsgroups\n",
      "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
      "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print type(twenty_train)\n",
      "print twenty_train.target_names\n",
      "print type(twenty_train.data)\n",
      "print type(twenty_train.target)\n",
      "print twenty_train.target.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'sklearn.datasets.base.Bunch'>\n",
        "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n",
        "<type 'list'>\n",
        "<type 'numpy.ndarray'>\n",
        "(2257,)\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print twenty_train.data[:1] # type list\n",
      "print twenty_train.target[:1] # type ndarray"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'From: sd345@city.ac.uk (Michael Collier)\\nSubject: Converting images to HP LaserJet III?\\nNntp-Posting-Host: hampton\\nOrganization: The City University\\nLines: 14\\n\\nDoes anyone know of a good way (standard PC application/PD utility) to\\nconvert tif/img/tga files into LaserJet III format.  We would also like to\\ndo the same, converting to HPGL (HP plotter) files.\\n\\nPlease email any response.\\n\\nIs this the correct group?\\n\\nThanks in advance.  Michael.\\n-- \\nMichael Collier (Programmer)                 The Computer Unit,\\nEmail: M.P.Collier@uk.ac.city                The City University,\\nTel: 071 477-8000 x3769                      London,\\nFax: 071 477-8565                            EC1V 0HB.\\n']\n",
        "[1]\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mnb_pl = Pipeline([\n",
      "    ('vect', CountVectorizer()),\n",
      "    ('tfidf', TfidfTransformer()),\n",
      "    ('clf', MultinomialNB())\n",
      "])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mnb_pl = mnb_pl.fit(twenty_train.data, twenty_train.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
      "docs_test = twenty_test.data\n",
      "print type(docs_test)\n",
      "print len(docs_test)\n",
      "print docs_test[:1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<type 'list'>\n",
        "1502\n",
        "[u\"From: brian@ucsd.edu (Brian Kantor)\\nSubject: Re: HELP for Kidney Stones ..............\\nOrganization: The Avant-Garde of the Now, Ltd.\\nLines: 12\\nNNTP-Posting-Host: ucsd.edu\\n\\nAs I recall from my bout with kidney stones, there isn't any\\nmedication that can do anything about them except relieve the pain.\\n\\nEither they pass, or they have to be broken up with sound, or they have\\nto be extracted surgically.\\n\\nWhen I was in, the X-ray tech happened to mention that she'd had kidney\\nstones and children, and the childbirth hurt less.\\n\\nDemerol worked, although I nearly got arrested on my way home when I barfed\\nall over the police car parked just outside the ER.\\n\\t- Brian\\n\"]\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predicted = mnb_pl.predict(docs_test)\n",
      "np.mean(predicted == twenty_test.target) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "0.83488681757656458"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Now Let's Use Our Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv(\"datasets/livewire_log_cumviews.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>title</th>\n",
        "      <th>views</th>\n",
        "      <th>log_views</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> Ancient Crimean Gold In Legal Limbo After Russ...</td>\n",
        "      <td>  1435</td>\n",
        "      <td>  7.268920</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> California Sec. Of State Candidate Arrested In...</td>\n",
        "      <td> 12418</td>\n",
        "      <td>  9.426902</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> Planet Biden: Scientists Nickname New Dwarf Pl...</td>\n",
        "      <td>  7351</td>\n",
        "      <td>  8.902592</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> Mass. Guv Candidate Passes Kidney Stone During...</td>\n",
        "      <td> 35843</td>\n",
        "      <td> 10.486904</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Charlotte's Brand New Mayor Turns Out To Be A ...</td>\n",
        "      <td>  8466</td>\n",
        "      <td>  9.043813</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "                                               title  views  log_views\n",
        "0  Ancient Crimean Gold In Legal Limbo After Russ...   1435   7.268920\n",
        "1  California Sec. Of State Candidate Arrested In...  12418   9.426902\n",
        "2  Planet Biden: Scientists Nickname New Dwarf Pl...   7351   8.902592\n",
        "3  Mass. Guv Candidate Passes Kidney Stone During...  35843  10.486904\n",
        "4  Charlotte's Brand New Mayor Turns Out To Be A ...   8466   9.043813"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = df.title.values\n",
      "Y = df.log_views\n",
      "print X.shape\n",
      "print Y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(7810,)\n",
        "(7810,)\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
      "print x_train.shape\n",
      "print x_test.shape\n",
      "print y_train.shape\n",
      "print y_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(5232,)\n",
        "(2578,)\n",
        "(5232,)\n",
        "(2578,)\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr_pl = Pipeline([\n",
      "    ('vect', CountVectorizer()),\n",
      "    ('tfidf', TfidfTransformer()),\n",
      "    ('clf', LinearRegression())\n",
      "])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr_pl = lr_pl.fit(x_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = lr_pl.predict(x_test)\n",
      "r2 = r2_score(y_test, predictions)\n",
      "ev = explained_variance_score(y_test, predictions)\n",
      "rmse = np.sqrt(np.mean((predictions - y_test)**2))\n",
      "print \"r2\", r2\n",
      "print \"ev\", ev\n",
      "print \"rmse\", rmse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "r2 -1.70068745489\n",
        "ev -1.70041763055\n",
        "rmse 2.13316688019\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "page_views = np.exp(lr_pl.predict(x_test[1]))\n",
      "print x_test[1]\n",
      "print \"predicted: %0.2f\" %(page_views[0])\n",
      "print \"actual: %0.2f\" %(np.exp(y_test[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NIH Official: 'Breach Of Protocol' Led To Health Worker Contracting Ebola\n",
        "predicted: 4948.64\n",
        "actual: 4018.00\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Custom Pipeline Tutorial"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Source:\n",
      "\n",
      "http://nbviewer.ipython.org/github/rasbt/pattern_classification/blob/master/machine_learning/scikit-learn/scikit-pipeline.ipynb\n",
      "http://stackoverflow.com/questions/25250654/how-can-i-use-a-custom-feature-selection-function-in-scikit-learns-pipeline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv(\"datasets/iris.csv\", header=None, sep=\",\")\n",
      "df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 5.1</td>\n",
        "      <td> 3.5</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 4.9</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 4.7</td>\n",
        "      <td> 3.2</td>\n",
        "      <td> 1.3</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 4.6</td>\n",
        "      <td> 3.1</td>\n",
        "      <td> 1.5</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 5.0</td>\n",
        "      <td> 3.6</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "     0    1    2    3            4\n",
        "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
        "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
        "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
        "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
        "4  5.0  3.6  1.4  0.2  Iris-setosa"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_dict = {i:label for i,label in zip(\n",
      "            range(4),\n",
      "              ('sepal length in cm', \n",
      "              'sepal width in cm', \n",
      "              'petal length in cm', \n",
      "              'petal width in cm', ))}\n",
      "feature_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "{0: 'sepal length in cm',\n",
        " 1: 'sepal width in cm',\n",
        " 2: 'petal length in cm',\n",
        " 3: 'petal width in cm'}"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = df[[0,1,2,3]].values \n",
      "y = df[4].values\n",
      "print X.shape\n",
      "print y.shape\n",
      "\n",
      "enc = LabelEncoder()\n",
      "label_encoder = enc.fit(y)\n",
      "y = label_encoder.transform(y) + 1\n",
      "\n",
      "label_dict = {1: 'Setosa', 2: 'Versicolor', 3:'Virginica'}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(150, 4)\n",
        "(150,)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=12345)\n",
      "print X_train.shape\n",
      "print y_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(90, 4)\n",
        "(90,)\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class ColumnSelector(object):\n",
      "    \"\"\" A feature selector for scikit-learn's Pipeline class that returns\n",
      "        specified columns from a numpy array.\n",
      "    \"\"\"\n",
      "    def __init__(self, cols):\n",
      "        self.cols = cols\n",
      "        \n",
      "    def transform(self, X, y=None):\n",
      "        return X[:, self.cols]\n",
      "\n",
      "    def fit(self, X, y=None):\n",
      "        return self"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# http://stackoverflow.com/questions/21165751/what-does-a-colon-and-comma-stand-in-a-python-list\n",
      "\n",
      "x = np.array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "print x[:]\n",
      "print x[:, (1,4,7)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0 1 2 3 4 5 6 7 8 9]]\n",
        "[[1 4 7]]\n"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 5.1</td>\n",
        "      <td> 3.5</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 4.9</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 4.7</td>\n",
        "      <td> 3.2</td>\n",
        "      <td> 1.3</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 4.6</td>\n",
        "      <td> 3.1</td>\n",
        "      <td> 1.5</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 5.0</td>\n",
        "      <td> 3.6</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "     0    1    2    3            4\n",
        "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
        "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
        "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
        "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
        "4  5.0  3.6  1.4  0.2  Iris-setosa"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cs = ColumnSelector(cols=(0,3,4))\n",
      "selected = cs.transform(df.values)\n",
      "selected[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "array([[5.1, 0.2, 'Iris-setosa'],\n",
        "       [4.9, 0.2, 'Iris-setosa'],\n",
        "       [4.7, 0.2, 'Iris-setosa'],\n",
        "       [4.6, 0.2, 'Iris-setosa'],\n",
        "       [5.0, 0.2, 'Iris-setosa']], dtype=object)"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ss = StandardScaler()\n",
      "scaled = ss.fit_transform(df[[0,1,2,3]].values)\n",
      "scaled[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 71,
       "text": [
        "array([[-0.90068117,  1.03205722, -1.3412724 , -1.31297673],\n",
        "       [-1.14301691, -0.1249576 , -1.3412724 , -1.31297673],\n",
        "       [-1.38535265,  0.33784833, -1.39813811, -1.31297673],\n",
        "       [-1.50652052,  0.10644536, -1.2844067 , -1.31297673],\n",
        "       [-1.02184904,  1.26346019, -1.3412724 , -1.31297673]])"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_all = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler()),           \n",
      "    ('classifier', GaussianNB())   \n",
      "    ])\n",
      "\n",
      "clf_petal = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler()),\n",
      "    ('reduce_dim', ColumnSelector(cols=(2,3))),    \n",
      "    ('classifier', GaussianNB())   \n",
      "    ]) \n",
      "\n",
      "clf_pca = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler()),    \n",
      "    ('reduce_dim', PCA(n_components=2)),\n",
      "    ('classifier', GaussianNB())   \n",
      "    ])\n",
      "\n",
      "clf_lda = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler()), \n",
      "    ('reduce_dim', LDA(n_components=2)),\n",
      "    ('classifier', GaussianNB())   \n",
      "    ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = KFold(n=X_train.shape[0],  # total number of samples\n",
      "           n_folds=5,           # number of folds the dataset is divided into\n",
      "           random_state=12345)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = [ cross_val_score(clf, X_train, y_train, cv=cv, scoring='accuracy')\n",
      "            for clf in [clf_all, clf_petal, clf_pca, clf_lda]\n",
      "         ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for score,label in zip(scores, \n",
      "                       ['all attributes', \n",
      "                        'Petal dimensions (column 3 & 4)',\n",
      "                        'PCA dim. red. (n=2)', \n",
      "                        'LDA dim. red. (n=2)', \n",
      "                        ]\n",
      "                       ):\n",
      "    print(\"Accuracy: {:.2%} (+/- {:.2%}), {:}\".format(score.mean(), score.std(), label))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy: 94.44% (+/- 3.51%), all attributes\n",
        "Accuracy: 94.44% (+/- 6.09%), Petal dimensions (column 3 & 4)\n",
        "Accuracy: 85.56% (+/- 9.69%), PCA dim. red. (n=2)\n",
        "Accuracy: 96.67% (+/- 4.44%), LDA dim. red. (n=2)\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_lda.fit(X_train, y_train)\n",
      "pred_test = clf_lda.predict(X_test)\n",
      "\n",
      "print('Prediction accuracy for the test dataset')\n",
      "print('{:.2%}'.format(accuracy_score(y_test, pred_test)))\n",
      "\n",
      "print('\\nConfusion Matrix of the Naive Bayes classifier')\n",
      "print(confusion_matrix(y_test, clf_lda.predict(X_test)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Prediction accuracy for the test dataset\n",
        "100.00%\n",
        "\n",
        "Confusion Matrix of the Naive Bayes classifier\n",
        "[[21  0  0]\n",
        " [ 0 22  0]\n",
        " [ 0  0 17]]\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Let's Try Writing Our Own Custom Pipeline Object"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class TitleExtractor:\n",
      "  def transform(self, data):\n",
      "    return np.asarray(data[['title']])\n",
      "\n",
      "  def fit(self, *_):\n",
      "    return self"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "title_extractor_pl = Pipeline([\n",
      "    ('title_ext', TitleExtractor()),\n",
      "    ('vect', CountVectorizer()),\n",
      "    ('tfidf', TfidfTransformer()),\n",
      "    ('clf', LinearRegression())\n",
      "])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = df\n",
      "Y = df.log_views\n",
      "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "title_extractor_pl = title_extractor_pl.fit(x_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-72-3b5a6a98238a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtitle_extractor_pl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitle_extractor_pl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mfit\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[0mdata\u001b[0m \u001b[0musing\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pre_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36m_pre_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                               \u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-69-7581f17e03d7>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTitleExtractor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Build a Compound Pipeline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline = Pipeline([\n",
      "  ('extract_essays', EssayExractor()),\n",
      "  ('features', FeatureUnion([\n",
      "    ('ngram_tf_idf', Pipeline([\n",
      "      ('counts', CountVectorizer()),\n",
      "      ('tf_idf', TfidfTransformer())\n",
      "    ])),\n",
      "    ('essay_length', LengthTransformer()),\n",
      "    ('misspellings', MispellingCountTransformer())\n",
      "  ])),\n",
      "  ('classifier', MultinomialNB())\n",
      "])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}