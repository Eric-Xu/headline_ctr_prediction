{
 "metadata": {
  "name": "",
  "signature": "sha256:021a86a2caf08681ee92ed1963ea4ba93ccd41ff943151a6bc759042456c88d4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import time\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "from nltk.stem.porter import PorterStemmer\n",
      "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.decomposition import PCA, TruncatedSVD\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.cross_validation import KFold"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1. Load Our Cleaned Headline Dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv(\"datasets/mediamatters_combined_cleaned.csv\")\n",
      "df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>SubCat</th>\n",
        "      <th>Headlines</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td>                      28865</td>\n",
        "      <td>                                             28864</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>unique</th>\n",
        "      <td>                         70</td>\n",
        "      <td>                                             28864</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>top</th>\n",
        "      <td> /issues/health-care-reform</td>\n",
        "      <td> Poll Deflates Right-Wing Claims About Undocume...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>freq</th>\n",
        "      <td>                       2818</td>\n",
        "      <td>                                                 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "                            SubCat  \\\n",
        "count                        28865   \n",
        "unique                          70   \n",
        "top     /issues/health-care-reform   \n",
        "freq                          2818   \n",
        "\n",
        "                                                Headlines  \n",
        "count                                               28864  \n",
        "unique                                              28864  \n",
        "top     Poll Deflates Right-Wing Claims About Undocume...  \n",
        "freq                                                    1  "
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = df.dropna()\n",
      "df.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 28864 entries, 0 to 28864\n",
        "Data columns (total 2 columns):\n",
        "SubCat       28864 non-null object\n",
        "Headlines    28864 non-null object\n",
        "dtypes: object(2)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2. Look at Some Sample Headlines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_sample_headlines(df, n):\n",
      "    sampler = np.random.permutation(len(df.Headlines))\n",
      "    print df.take(sampler[:n]).Headlines"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_sample_headlines(df, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "26927    Dobbs chastises pitiful press corps for framin...\n",
        "26281    Beck continues his bizarre fascination with pi...\n",
        "21048      Limbaugh: Imam Rauf sounds like Jeremiah Wright\n",
        "18227    Hannity branded Emanuel one of the hardest lef...\n",
        "25448    Hannity On Obamas Jobs Plan: I Think Hes Doubl...\n",
        "15077    Hannity twists Wash. Post report to claim the ...\n",
        "14807    Fox  Friends Interprets Obamas Praise Of Safet...\n",
        "22089    Hannity paraphrased passage from Corsis book t...\n",
        "25255    Limbaugh Doesnt Remember What Hes Talking Abou...\n",
        "9191     Cyber Monday Special: Buy Guns Before Obama En...\n",
        "Name: Headlines, dtype: object\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 3. Apply Porter Stemming Algorithm to Reduce Vocabulary Size"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "porter = PorterStemmer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def apply_porter_stem(sentence):\n",
      "    stemmed = \" \".join(PorterStemmer().stem_word(word) for word in sentence.split(\" \"))\n",
      "    return stemmed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence = \"Stemming is funnier than a bummer says the sushi loving computer scientist\"\n",
      "apply_porter_stem(sentence)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "u'Stem is funnier than a bummer say the sushi love comput scientist'"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[\"Headlines\"] = df.Headlines.apply(lambda x: apply_porter_stem(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_sample_headlines(df, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12441    Fox Give Anti-Immigr Platform To Attack Americ...\n",
        "24272    Karl Rove Absolv GOP Of Blame For Debt Ceil Ho...\n",
        "16223    Wash. Post Capehart Highlight Equaliti Matter ...\n",
        "15465    Beck Theory: Richard Trumka And AFL-CIO Using ...\n",
        "10229    Fox Nation: America Rising: Obamacar Repeal in...\n",
        "7170     Hannity: Modern Femin Is All About Abortion An...\n",
        "12451    Limbaugh On A Space Alien Invasion: Some Peopl...\n",
        "27087    Hanniti distort articl to hit media for credit...\n",
        "5703     Brook respons to Palin death panel Facebook po...\n",
        "22508         Ann Coulter turn up the heat on Nanci Reagan\n",
        "Name: Headlines, dtype: object\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv(\"datasets/mediamatters_combined_stemmed.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 4. Generate a Matrix of Word Counts with CountVectorizer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_count_vectors(corpus, n):\n",
      "    vectorizer = CountVectorizer(stop_words=\"english\", ngram_range=(1,2), lowercase=True, max_features=n)\n",
      "    # vectorizer = CountVectorizer(stop_words = \"english\", ngram_range=(1,2), lowercase = True) # (28864, 167460)\n",
      "    return vectorizer.fit_transform(corpus), vectorizer.fit(corpus)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_feature_count = 500\n",
      "X500_vec, fitted500_vec = get_count_vectors(df.Headlines, max_feature_count)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Get a Sample of the Most Frequent Terms"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def list_term_freq(vec, X, n):\n",
      "    word_freq_df = pd.DataFrame({'term': vec.get_feature_names(), 'occurrences':np.asarray(X.sum(axis=0)).ravel().tolist()})\n",
      "    word_freq_df['frequency'] = word_freq_df['occurrences']/np.sum(word_freq_df['occurrences'])\n",
      "    print word_freq_df.sort('occurrences',ascending = False).head(n)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list_term_freq(vectorizer, X500_vec, 15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "     occurrences      term  frequency\n",
        "175         6663       fox   0.041769\n",
        "312         5051     obama   0.031664\n",
        "77          3012     claim   0.018882\n",
        "264         2774  limbaugh   0.017390\n",
        "282         2564     media   0.016073\n",
        "303         2319       new   0.014537\n",
        "36          2009      beck   0.012594\n",
        "162         1867      fals   0.011704\n",
        "28          1839    attack   0.011528\n",
        "388         1734     right   0.010870\n",
        "380         1543    report   0.009673\n",
        "207         1477    health   0.009259\n",
        "400         1277       say   0.008005\n",
        "180         1244   fox new   0.007798\n",
        "59          1239      care   0.007767\n"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Vocabulary Size"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Shape of the count vectors\", X500_vec.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Shape of the count vectors (28864, 500)\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 5. Using PCA to Summarize High Dimensional Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Reduce the dimensionality of the count vector\"\n",
      "# pca = PCA(n_components=500) # leads to Kernel death\n",
      "# pca = TruncatedSVD(n_components=10000) # takes too long\n",
      "# pca = TruncatedSVD(n_components=500) # 34% accuracy score vs 54% by RandomForest with 10000 features\n",
      "# X_pca = pca.fit_transform(X500_vec.toarray())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reduce the dimensionality of the count vector\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Vocabulary Size After PCA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Shape of the pca components\", X_pca.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Shape of the pca components (28864, 500)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 6. Transform Count Vectors to TF-IDF"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf_transformer = TfidfTransformer() \n",
      "X_tfidf = tfidf_transformer.fit_transform(X500_vec)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 7. Compare Multiclass Baseline Classifiers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_test_train_sets(X, Y):\n",
      "    return train_test_split(X, Y, test_size=0.33, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "multiclass_clfs = {'BernoulliNB': BernoulliNB(),\n",
      "                   'MultinomialNB': MultinomialNB(),\n",
      "                   'GaussianNB': GaussianNB(),\n",
      "                   'KNeighbors': KNeighborsClassifier(),\n",
      "                   'DecisionTree': DecisionTreeClassifier(),\n",
      "                   'RandomForest': RandomForestClassifier(),\n",
      "                   'SGDClassifier': SGDClassifier(),\n",
      "                   'LinearDiscriminant': LDA()}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_score(classifiers, X, Y):\n",
      "    x_train, x_test, y_train, y_test = create_test_train_sets(X, Y)\n",
      "    for name, clf in classifiers.items():\n",
      "        start = time.time()\n",
      "        clf.fit(x_train.toarray(), y_train)\n",
      "        score = clf.score(x_test.toarray(), y_test)\n",
      "        time_elapsed = time.time() - start\n",
      "        print \"%s produced an accuracy score of %0.4f in %0.2f seconds\"% (name, score, time_elapsed)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### X = count vectors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_score(multiclass_clfs, X500_vec, df.SubCat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DecisionTree produced an accuracy score of 0.3694 in 12.44 seconds\n",
        "BernoulliNB produced an accuracy score of 0.4437 in 0.38 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "SGDClassifier produced an accuracy score of 0.4361 in 4.20 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LinearDiscriminant produced an accuracy score of 0.4112 in 4.71 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "MultinomialNB produced an accuracy score of 0.4426 in 0.28 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GaussianNB produced an accuracy score of 0.0890 in 4.16 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "RandomForest produced an accuracy score of 0.4139 in 4.43 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "KNeighbors produced an accuracy score of 0.2622 in 142.51 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### X = TF-IDF"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_score(multiclass_clfs, X_tfidf, df.SubCat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DecisionTree produced an accuracy score of 0.3773 in 19.83 seconds\n",
        "BernoulliNB produced an accuracy score of 0.4437 in 0.31 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "SGDClassifier produced an accuracy score of 0.4415 in 4.84 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LinearDiscriminant produced an accuracy score of 0.4112 in 5.72 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "MultinomialNB produced an accuracy score of 0.4198 in 0.29 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GaussianNB produced an accuracy score of 0.0917 in 4.42 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "RandomForest produced an accuracy score of 0.4288 in 6.01 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "KNeighbors produced an accuracy score of 0.2990 in 134.76 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Let's Try Increasing CountVectorizer's Top Features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_feature_count = 1000\n",
      "X1000_vec, fitted1000_vec = get_count_vectors(df.Headlines, max_feature_count)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_score(multiclass_clfs, X1000_vec, df.SubCat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DecisionTree produced an accuracy score of 0.4379 in 39.37 seconds\n",
        "BernoulliNB produced an accuracy score of 0.4941 in 0.70 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "SGDClassifier produced an accuracy score of 0.4955 in 8.26 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LinearDiscriminant produced an accuracy score of 0.4779 in 17.11 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "MultinomialNB produced an accuracy score of 0.4940 in 0.48 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GaussianNB produced an accuracy score of 0.1537 in 8.28 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "RandomForest produced an accuracy score of 0.4772 in 11.95 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "KNeighbors produced an accuracy score of 0.2589 in 297.73 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get_score(multiclass_clfs, X700_vec, df.SubCat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DecisionTree produced an accuracy score of 0.4058 in 22.89 seconds\n",
        "BernoulliNB produced an accuracy score of 0.4711 in 0.49 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "SGDClassifier produced an accuracy score of 0.4706 in 6.07 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LinearDiscriminant produced an accuracy score of 0.4444 in 9.04 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "MultinomialNB produced an accuracy score of 0.4690 in 0.44 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GaussianNB produced an accuracy score of 0.1182 in 5.85 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "RandomForest produced an accuracy score of 0.4471 in 6.59 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "KNeighbors produced an accuracy score of 0.2623 in 206.88 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/site-packages/sklearn/lda.py:161: UserWarning: Variables are collinear\n",
        "  warnings.warn(\"Variables are collinear\")\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get_score(multiclass_clfs, X500_vec, df.SubCat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DecisionTree produced an accuracy score of 0.3697 in 15.06 seconds\n",
        "BernoulliNB produced an accuracy score of 0.4437 in 0.48 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "SGDClassifier produced an accuracy score of 0.4361 in 6.77 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LinearDiscriminant produced an accuracy score of 0.4112 in 7.88 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "MultinomialNB produced an accuracy score of 0.4426 in 0.30 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GaussianNB produced an accuracy score of 0.0890 in 4.46 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "RandomForest produced an accuracy score of 0.4158 in 4.67 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "KNeighbors produced an accuracy score of 0.2622 in 141.06 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get_score(multiclass_clfs, X250_vec, df.SubCat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DecisionTree produced an accuracy score of 0.3124 in 4.46 seconds\n",
        "BernoulliNB produced an accuracy score of 0.3984 in 0.22 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "SGDClassifier produced an accuracy score of 0.3657 in 2.43 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LinearDiscriminant produced an accuracy score of 0.3606 in 1.66 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "MultinomialNB produced an accuracy score of 0.3905 in 0.19 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GaussianNB produced an accuracy score of 0.0639 in 2.11 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "RandomForest produced an accuracy score of 0.3592 in 2.43 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "KNeighbors produced an accuracy score of 0.2508 in 66.97 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Bernoulli wins both accuracy of prediction and speed.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Bernoulli wins both accuracy of prediction and speed.\n"
       ]
      }
     ],
     "prompt_number": 128
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 8. Parameter Tuning with KFolds"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### First Let's Raise CountVectorizer's Top Features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_feature_count = 4000\n",
      "X4000_vec, fitted4000_vec = get_count_vectors(df.Headlines, max_feature_count)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tune_bernoulli_alpha():\n",
      "    cv_accuracies = []\n",
      "    kfold = KFold(len(df), n_folds=100)\n",
      "    nalphas = range(1,10)\n",
      "\n",
      "    for i in nalphas:\n",
      "        X, Y = X4000_vec, df.SubCat\n",
      "        accuracies = []\n",
      "        for train, test in kfold:\n",
      "            x_train, y_train, x_test, y_test = X[train], Y[train], X[test], Y[test]   \n",
      "            clf = BernoulliNB(alpha = i)\n",
      "            clf.fit(x_train, y_train)\n",
      "            score = clf.score(x_test, y_test)\n",
      "            accuracies.append(score)\n",
      "        mean_accuracy = np.mean(accuracies)\n",
      "        print \"Bernoulli (alpha=%s) had an accuracy score of %0.4f\"% (i, mean_accuracy)\n",
      "        cv_errors.append(score)\n",
      "\n",
      "#     plt.plot(nalphas, cv_accuracies)\n",
      "#     plt.xlabel(\"Alpha Value\")\n",
      "#     plt.ylabel(\"Accuracy Score\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tune_bernoulli_alpha()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Bernoulli (alpha=1) had an accuracy score of 0.3866\n",
        "Bernoulli (alpha=2) had an accuracy score of 0.3611"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Bernoulli (alpha=3) had an accuracy score of 0.3315"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Bernoulli (alpha=4) had an accuracy score of 0.3006"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Bernoulli (alpha=5) had an accuracy score of 0.2735"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Bernoulli (alpha=6) had an accuracy score of 0.2500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Bernoulli (alpha=7) had an accuracy score of 0.2325"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Bernoulli (alpha=8) had an accuracy score of 0.2174"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Bernoulli (alpha=9) had an accuracy score of 0.2064"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 191
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 9. Using BernoulliNB(alpha=1) with 4000 Count Vectorizer Features, The Results Are..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_categories(headline, clf):\n",
      "    headline_vec = fitted4000_vec.transform([headline])\n",
      "    probs = clf.predict_proba(headline_vec.toarray())\n",
      "    tags = clf.classes_\n",
      "    zipped = [zip(i, tags) for i in probs]\n",
      "    zipped[0].sort(key = lambda t: t[0], reverse = True)\n",
      "    print_predictions(zipped[0][:3])\n",
      "    \n",
      "def print_predictions(results):\n",
      "    print \"The top three categories judged by the classifier are...\"\n",
      "    for prob, cat in results:\n",
      "        print \"%s with probability %02f percent.\" %(cat, prob * 100)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_train, x_test, y_train, y_test = create_test_train_sets(X4000_vec, df.SubCat)\n",
      "bnb = BernoulliNB().fit(x_train.toarray(), y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_headline = \"How Right-Wing Media Finally Benghazified O-care With \u2018Gruber-Gate\u2019\"\n",
      "predict_categories(new_headline, bnb)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The top three categories judged by the classifier are...\n",
        "/issues/race-ethnicity with probability 48.451771 percent.\n",
        "/issues/guns with probability 16.167530 percent.\n",
        "/issues/health-care-reform with probability 10.577524 percent.\n"
       ]
      }
     ],
     "prompt_number": 194
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_headline = \"Kansas Gov. Brownback's Budget Shortfall Solution: Spending Cuts!\"\n",
      "predict_categories(new_headline, bnb)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The top three categories judged by the classifier are...\n",
        "/issues/budget with probability 90.880937 percent.\n",
        "/issues/health-care-reform with probability 2.797890 percent.\n",
        "/issues/cabinet-agencies with probability 1.521819 percent.\n"
       ]
      }
     ],
     "prompt_number": 195
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_headline = \"The Most Horrific Revelations In The CIA Torture Report\"\n",
      "predict_categories(new_headline, bnb)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The top three categories judged by the classifier are...\n",
        "/issues/climate-change with probability 29.747079 percent.\n",
        "/issues/war-in-iraq with probability 16.664215 percent.\n",
        "/issues/the-presidency-white-house with probability 11.468216 percent.\n"
       ]
      }
     ],
     "prompt_number": 197
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_headline = \"Police Union Calls For De Blasio To Be Barred From Officers' Funerals\"\n",
      "predict_categories(new_headline, bnb)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The top three categories judged by the classifier are...\n",
        "/issues/the-presidency-white-house with probability 40.240654 percent.\n",
        "/issues/health-care-reform with probability 32.285503 percent.\n",
        "/issues/race-ethnicity with probability 5.666232 percent.\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}