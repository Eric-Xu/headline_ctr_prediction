{
 "metadata": {
  "name": "",
  "signature": "sha256:c70c101a68c7878c0e85a57695d3b5801f42283a7388a528222b7ca327b9d089"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import nltk\n",
      "from nltk.stem.porter import PorterStemmer\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import Lasso\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn.feature_selection import SelectKBest\n",
      "from sklearn.feature_selection import f_regression\n",
      "from sklearn.cross_validation import KFold\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.metrics import mean_squared_error\n",
      "from collections import Counter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# nltk.download()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "showing info http://nltk.github.com/nltk_data/\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv(\"datasets/livewire_hits2.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_sample = pd.DataFrame(columns = [\"title\", \"day_0_count\"])\n",
      "df_sample.title = df.title\n",
      "df_sample.day_0_count = df.day_0\n",
      "df_sample.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "(7812, 2)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Part-of-speech (POS) Tagging"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_pos_tags(text):\n",
      "    tokens = nltk.word_tokenize(text.lower())\n",
      "    text = nltk.Text(tokens)\n",
      "    tags = nltk.pos_tag(text)\n",
      "    return tags"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = df_sample.title[0]\n",
      "get_pos_tags(text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 242,
       "text": [
        "[('ancient', 'NN'),\n",
        " ('crimean', 'VBD'),\n",
        " ('gold', 'NN'),\n",
        " ('in', 'IN'),\n",
        " ('legal', 'JJ'),\n",
        " ('limbo', 'NN'),\n",
        " ('after', 'IN'),\n",
        " ('russia', 'NN'),\n",
        " (\"'s\", 'POS'),\n",
        " ('invasion', 'NN')]"
       ]
      }
     ],
     "prompt_number": 242
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Get counts for each POS type"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_pos_counts(text):\n",
      "    tags = get_pos_tags(text)\n",
      "    counts = Counter(tag for word,tag in tags)\n",
      "    return dict(counts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print text\n",
      "get_pos_counts(text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Ancient Crimean Gold In Legal Limbo After Russia's Invasion\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 79,
       "text": [
        "Counter({'NN': 5, 'IN': 2, 'POS': 1, 'JJ': 1, 'VBD': 1})"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.help.upenn_tagset('NN')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NN: noun, common, singular or mass\n",
        "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
        "    investment slide humour falloff slick wind hyena override subhumanity\n",
        "    machinist ...\n"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Get percentages for each POS type"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_pos_perc(text):\n",
      "    counts = get_pos_counts(text)\n",
      "    total = sum(counts.values())\n",
      "    percentages = dict((word, float(count)/total) for word,count in counts.items())\n",
      "    return percentages\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print text\n",
      "print get_pos_counts(text)\n",
      "print get_pos_perc(text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Ancient Crimean Gold In Legal Limbo After Russia's Invasion\n",
        "Counter({'NN': 5, 'IN': 2, 'POS': 1, 'JJ': 1, 'VBD': 1})\n",
        "{'VBD': 0.1, 'NN': 0.5, 'POS': 0.1, 'JJ': 0.1, 'IN': 0.2}\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Add POS Columns"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_sample.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 96,
       "text": [
        "Index([u'title', u'day_0_count'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for idx, row in df_sample.iterrows():\n",
      "    text = unicode(str(row.title), encoding='utf-8')\n",
      "    percentages = get_pos_perc(text)\n",
      "    for tag, pct in percentages.iteritems():\n",
      "        if tag not in df_sample.columns:\n",
      "            df_sample[tag] = 0.0\n",
      "        df_sample[tag][idx] = round(pct, 4)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_sample.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>title</th>\n",
        "      <th>day_0_count</th>\n",
        "      <th>JJ</th>\n",
        "      <th>IN</th>\n",
        "      <th>POS</th>\n",
        "      <th>NN</th>\n",
        "      <th>VBD</th>\n",
        "      <th>.</th>\n",
        "      <th>VBN</th>\n",
        "      <th>DT</th>\n",
        "      <th>...</th>\n",
        "      <th>WDT</th>\n",
        "      <th>JJR</th>\n",
        "      <th>#</th>\n",
        "      <th>JJS</th>\n",
        "      <th>EX</th>\n",
        "      <th>RBR</th>\n",
        "      <th>LS</th>\n",
        "      <th>PDT</th>\n",
        "      <th>``</th>\n",
        "      <th>WP$</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> Ancient Crimean Gold In Legal Limbo After Russ...</td>\n",
        "      <td>  1332</td>\n",
        "      <td> 0.1000</td>\n",
        "      <td> 0.2000</td>\n",
        "      <td> 0.1000</td>\n",
        "      <td> 0.5000</td>\n",
        "      <td> 0.1000</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> California Sec. Of State Candidate Arrested In...</td>\n",
        "      <td> 10743</td>\n",
        "      <td> 0.0769</td>\n",
        "      <td> 0.2308</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.4615</td>\n",
        "      <td> 0.1538</td>\n",
        "      <td> 0.0769</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> Planet Biden: Scientists Nickname New Dwarf Pl...</td>\n",
        "      <td>  4907</td>\n",
        "      <td> 0.0909</td>\n",
        "      <td> 0.0909</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.3636</td>\n",
        "      <td> 0.0909</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0909</td>\n",
        "      <td> 0.0909</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> Mass. Guv Candidate Passes Kidney Stone During...</td>\n",
        "      <td> 27494</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.1111</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.6667</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.1111</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Charlotte's Brand New Mayor Turns Out To Be A ...</td>\n",
        "      <td>  6747</td>\n",
        "      <td> 0.0909</td>\n",
        "      <td> 0.0909</td>\n",
        "      <td> 0.0909</td>\n",
        "      <td> 0.3636</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0909</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 42 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "                                               title  day_0_count      JJ  \\\n",
        "0  Ancient Crimean Gold In Legal Limbo After Russ...         1332  0.1000   \n",
        "1  California Sec. Of State Candidate Arrested In...        10743  0.0769   \n",
        "2  Planet Biden: Scientists Nickname New Dwarf Pl...         4907  0.0909   \n",
        "3  Mass. Guv Candidate Passes Kidney Stone During...        27494  0.0000   \n",
        "4  Charlotte's Brand New Mayor Turns Out To Be A ...         6747  0.0909   \n",
        "\n",
        "       IN     POS      NN     VBD       .     VBN      DT   ...    WDT  JJR  \\\n",
        "0  0.2000  0.1000  0.5000  0.1000  0.0000  0.0000  0.0000   ...      0    0   \n",
        "1  0.2308  0.0000  0.4615  0.1538  0.0769  0.0000  0.0000   ...      0    0   \n",
        "2  0.0909  0.0000  0.3636  0.0909  0.0000  0.0909  0.0909   ...      0    0   \n",
        "3  0.1111  0.0000  0.6667  0.0000  0.1111  0.0000  0.0000   ...      0    0   \n",
        "4  0.0909  0.0909  0.3636  0.0000  0.0000  0.0000  0.0909   ...      0    0   \n",
        "\n",
        "   #  JJS  EX  RBR  LS  PDT  ``  WP$  \n",
        "0  0    0   0    0   0    0   0    0  \n",
        "1  0    0   0    0   0    0   0    0  \n",
        "2  0    0   0    0   0    0   0    0  \n",
        "3  0    0   0    0   0    0   0    0  \n",
        "4  0    0   0    0   0    0   0    0  \n",
        "\n",
        "[5 rows x 42 columns]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Double check that tag column percentages sum up to 1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tag_cols = [col for col in df_sample.columns if col not in [\"title\", \"day_0_count\"]]\n",
      "print tag_cols"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['JJ', 'IN', 'POS', 'NN', 'VBD', '.', 'VBN', 'DT', ':', 'NNS', 'VB', 'TO', '-NONE-', 'VBZ', 'VBP', \"''\", 'RB', 'NNP', 'MD', 'RP', 'PRP', 'VBG', 'CD', 'WRB', '$', 'CC', ',', 'WP', 'RBS', 'PRP$', 'WDT', 'JJR', '#', 'JJS', 'EX', 'RBR', 'LS', 'PDT', '``', 'WP$']\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_sample[tag_cols].sum(axis=1)[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "0    1.0000\n",
        "1    0.9999\n",
        "2    0.9999\n",
        "3    1.0000\n",
        "4    0.9999\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for tag in tag_cols[:5]:\n",
      "    print nltk.help.upenn_tagset(tag)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "VBD: verb, past tense\n",
        "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
        "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
        "    speculated wore appreciated contemplated ...\n",
        "None\n",
        "NN: noun, common, singular or mass\n",
        "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
        "    investment slide humour falloff slick wind hyena override subhumanity\n",
        "    machinist ...\n",
        "None\n",
        "POS: genitive marker\n",
        "    ' 's\n",
        "None\n",
        "JJ: adjective or numeral, ordinal\n",
        "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
        "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
        "    multilingual multi-disciplinary ...\n",
        "None\n",
        "IN: preposition or conjunction, subordinating\n",
        "    astride among uppon whether out inside pro despite on by throughout\n",
        "    below within for towards near behind atop around if like until below\n",
        "    next into if beside ...\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Lets train a Random Forest to rank POS tags as features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.feature_extraction.text import CountVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf_model = RandomForestClassifier(random_state=0)\n",
      "rf_model.fit(df_sample[tag_cols], df_sample.day_0_count)\n",
      "\n",
      "# This prints the top 10 most important features\n",
      "print sorted(zip(rf_model.feature_importances_, tag_cols), reverse=True)[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0.10647531711284812, 'NN'), (0.081780730156028741, 'IN'), (0.079549916153464545, 'NNS'), (0.076968918487396329, 'JJ'), (0.055825389879610297, ':'), (0.045875578752382289, 'VBZ'), (0.045591348328815978, 'VBD'), (0.0443031963027984, 'RB'), (0.040292787435519957, 'VBP'), (0.038416398847855707, 'DT')]\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Sklearns approach"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "importances = rf_model.feature_importances_\n",
      "indices = np.argsort(importances)[::-1]\n",
      "\n",
      "# Print the feature ranking\n",
      "print(\"Feature ranking:\")\n",
      "\n",
      "for f in range(10):\n",
      "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], tag_cols[indices[f]], importances[indices[f]]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Feature ranking:\n",
        "1. feature 1 NN (0.106475)\n",
        "2. feature 4 IN (0.081781)\n",
        "3. feature 9 NNS (0.079550)\n",
        "4. feature 3 JJ (0.076969)\n",
        "5. feature 8 : (0.055825)\n",
        "6. feature 13 VBZ (0.045876)\n",
        "7. feature 0 VBD (0.045591)\n",
        "8. feature 15 RB (0.044303)\n",
        "9. feature 14 VBP (0.040293)\n",
        "10. feature 7 DT (0.038416)\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Let's See Which POS Columns SelectKBest Returns"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_test_train_sets(X, Y):\n",
      "    return train_test_split(X, Y, test_size=0.33, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Set Up Training and Test Datasets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = df_sample[tag_cols]\n",
      "Y = df_sample.day_0_count\n",
      "x_train, x_test, y_train, y_test = create_test_train_sets(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Run a Baseline Linear Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reg = LinearRegression()\n",
      "reg.fit(x_train, y_train)\n",
      "ypred = reg.predict(x_test)\n",
      "print np.sqrt(mean_squared_error(ypred, y_test))\n",
      "print x_train.shape\n",
      "print y_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "18135.510934\n",
        "(5234, 40)\n",
        "(5234,)\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = df_sample[tag_cols]\n",
      "Y = df_sample.day_0_count\n",
      "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33)\n",
      "\n",
      "b = SelectKBest(f_regression, k=10)\n",
      "b.fit(x_train, y_train)\n",
      "x_train = x_train[:, b.get_support()]\n",
      "x_test = x_test[:, b.get_support()]\n",
      "\n",
      "print b.get_support(indices=True)\n",
      "# [ 1  2  4  7       10 11          18    22            31 32]\n",
      "# [ 1  2  4     8    10 11       17 18    22               32]\n",
      "# [ 1  2  4          10 11       17 18 19 22               32]\n",
      "# [ 1  2  4          10 11       17 18    22         29    32]\n",
      "# [ 1     4  7     9 10 11    14    18    22 24]\n",
      "# [ 1     4  7     9 10 11    14    18    22               32]\n",
      "# [ 1     4  7       10 11    14    18    22 24            32]\n",
      "# [ 1     4  7     9 10 11          18    22 24   27]\n",
      "# [ 1     4  7     9 10 11 13 14    18    22]\n",
      "# [ 1     4        9 10 11       17 18 19 22    26]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 1  4  7  9 10 11 14 18 22 24]\n"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Top Features Selected by SelectKBest"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print tag_cols[1], tag_cols[4], tag_cols[10], tag_cols[11], tag_cols[18], tag_cols[22]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NN IN VB TO MD CD\n"
       ]
      }
     ],
     "prompt_number": 253
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top_pos = [\"NN\", \"IN\", \"VB\", \"TO\", \"MD\", \"CD\"]\n",
      "for pos in top_pos:\n",
      "    print nltk.help.upenn_tagset(pos)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NN: noun, common, singular or mass\n",
        "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
        "    investment slide humour falloff slick wind hyena override subhumanity\n",
        "    machinist ...\n",
        "None\n",
        "IN: preposition or conjunction, subordinating\n",
        "    astride among uppon whether out inside pro despite on by throughout\n",
        "    below within for towards near behind atop around if like until below\n",
        "    next into if beside ...\n",
        "None\n",
        "VB: verb, base form\n",
        "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
        "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
        "    boost brace break bring broil brush build ...\n",
        "None\n",
        "TO: \"to\" as preposition or infinitive marker\n",
        "    to\n",
        "None\n",
        "MD: modal auxiliary\n",
        "    can cannot could couldn't dare may might must need ought shall should\n",
        "    shouldn't will would\n",
        "None\n",
        "CD: numeral, cardinal\n",
        "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
        "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
        "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 254
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_count_by_pos(text, tag):\n",
      "    return [token for token, pos in nltk.pos_tag(nltk.word_tokenize(text.lower())) if pos.startswith(tag)]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 255
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence = \"Rising Income Inequality Causing Wealthy Americans To Take On Second Sailboat\"\n",
      "for tag in top_pos:\n",
      "    print tag, get_count_by_pos(sentence, tag)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NN ['income', 'inequality', 'americans', 'sailboat']\n",
        "IN ['on']\n",
        "VB ['rising', 'causing', 'take']\n",
        "TO ['to']\n",
        "MD "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[]\n",
        "CD []\n"
       ]
      }
     ],
     "prompt_number": 257
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Run Linear Regression Using KFolds"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = df_sample[list(tag_cols)].values\n",
      "Y = df_sample.day_0_count\n",
      "print X\n",
      "print Y\n",
      "print X.shape\n",
      "print Y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.1     0.2     0.1    ...,  0.      0.      0.    ]\n",
        " [ 0.0769  0.2308  0.     ...,  0.      0.      0.    ]\n",
        " [ 0.0909  0.0909  0.     ...,  0.      0.      0.    ]\n",
        " ..., \n",
        " [ 0.      0.0833  0.     ...,  0.      0.      0.    ]\n",
        " [ 0.      0.125   0.     ...,  0.      0.      0.    ]\n",
        " [ 0.      0.      0.1111 ...,  0.      0.      0.    ]]\n",
        "0      1332\n",
        "1     10743\n",
        "2      4907\n",
        "3     27494\n",
        "4      6747\n",
        "5      2784\n",
        "6      5777\n",
        "7      4017\n",
        "8      3498\n",
        "9      5366\n",
        "10     3836\n",
        "11     4172\n",
        "12     2442\n",
        "13     2205\n",
        "14     7149\n",
        "...\n",
        "7797      793\n",
        "7798     3805\n",
        "7799     4580\n",
        "7800    36417\n",
        "7801    16748\n",
        "7802     1090\n",
        "7803    17884\n",
        "7804     2406\n",
        "7805     8188\n",
        "7806     7264\n",
        "7807     5174\n",
        "7808     4113\n",
        "7809     9804\n",
        "7810    16735\n",
        "7811     1482\n",
        "Name: day_0_count, Length: 7812, dtype: int64\n",
        "(7812, 40)\n",
        "(7812,)\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kfold = KFold(len(X))\n",
      "for train, test in kfold:\n",
      "    x_train, x_test, y_train, y_test = X[train], Y[train], X[test], Y[test]\n",
      "    reg = LinearRegression()\n",
      "    reg.fit(df_sample[tag_cols], Y)\n",
      "    ypred = reg.predict(x_test)\n",
      "    print np.sqrt(mean_squared_error(ypred, y_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "shapes (5208,) and (40,) not aligned: 5208 (dim 0) != 40 (dim 0)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-20-7c7b4915993f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0m_center_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_asarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m--> 136\u001b[0;31m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/extmath.pyc\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfast_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: shapes (5208,) and (40,) not aligned: 5208 (dim 0) != 40 (dim 0)"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 05_model_selection/lab/cross_validation.ipynb"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import combinations\n",
      "from collections import defaultdict\n",
      "\n",
      "model_map = {'linreg': LinearRegression,\n",
      "             'ridge': Ridge,\n",
      "             'lasso': Lasso }\n",
      "\n",
      "def cv_model(X, y, test, train, reg_model='linreg'):\n",
      "    Xtrain, ytrain, Xtest, ytest = X[train], y[train], X[test], y[test]\n",
      "    model = model_map[reg_model](normalize=False, fit_intercept=True)\n",
      "    model.fit(X, y)\n",
      "    ypred = model.predict(Xtest)\n",
      "    return mean_squared_error(ypred, ytest)\n",
      "\n",
      "def cv_subset_selector(df, predictors):\n",
      "    cv_errors = defaultdict(lambda: defaultdict(list))\n",
      "    for r in range(2, len(predictors)+1):\n",
      "        for predictor_combos in combinations(predictors, r=r):        \n",
      "            X = df_sample[list(predictor_combos)].values\n",
      "            y = df_sample[\"day_0_count\"].values\n",
      "            kfold = KFold(len(df), n_folds=10)\n",
      "            mean_sq_errs = defaultdict(list)\n",
      "            for train, test in kfold:\n",
      "                for m in model_map.keys():\n",
      "                    mse = cv_model(X, y, test, train, m)\n",
      "                    mean_sq_errs[m].append(mse)\n",
      "            for m, vals in mean_sq_errs.iteritems():\n",
      "                model_df = pd.DataFrame()\n",
      "                cv_errors['_'.join(predictor_combos)][m] = np.mean(vals)\n",
      "    return cv_errors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 229
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv_errors = cv_subset_selector(df_sample, tag_cols[:15])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 258
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv_errors_df = pd.DataFrame.from_dict(cv_errors, orient='index')\n",
      "cv_errors_df = cv_errors_df.sort('linreg', ascending=False)\n",
      "print cv_errors_df.tail(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                                                            linreg  \\\n",
        "VBD_NN_POS_JJ_IN_._VBN_DT_NNS_VB_TO_-NONE-_VBZ_VBP    4.267911e+08   \n",
        "VBD_NN_POS_JJ_IN_VBN_DT_:_VB_TO_-NONE-_VBZ_VBP        4.267906e+08   \n",
        "VBD_NN_POS_JJ_IN_VBN_DT_:_NNS_VB_TO_-NONE-_VBZ_VBP    4.267904e+08   \n",
        "VBD_NN_POS_JJ_IN_._VBN_DT_:_VB_TO_-NONE-_VBZ_VBP      4.267900e+08   \n",
        "VBD_NN_POS_JJ_IN_._VBN_DT_:_NNS_VB_TO_-NONE-_VBZ_VBP  4.267898e+08   \n",
        "\n",
        "                                                             ridge  \\\n",
        "VBD_NN_POS_JJ_IN_._VBN_DT_NNS_VB_TO_-NONE-_VBZ_VBP    4.268050e+08   \n",
        "VBD_NN_POS_JJ_IN_VBN_DT_:_VB_TO_-NONE-_VBZ_VBP        4.268043e+08   \n",
        "VBD_NN_POS_JJ_IN_VBN_DT_:_NNS_VB_TO_-NONE-_VBZ_VBP    4.268042e+08   \n",
        "VBD_NN_POS_JJ_IN_._VBN_DT_:_VB_TO_-NONE-_VBZ_VBP      4.268038e+08   \n",
        "VBD_NN_POS_JJ_IN_._VBN_DT_:_NNS_VB_TO_-NONE-_VBZ_VBP  4.268037e+08   \n",
        "\n",
        "                                                             lasso  \n",
        "VBD_NN_POS_JJ_IN_._VBN_DT_NNS_VB_TO_-NONE-_VBZ_VBP    4.268104e+08  \n",
        "VBD_NN_POS_JJ_IN_VBN_DT_:_VB_TO_-NONE-_VBZ_VBP        4.268096e+08  \n",
        "VBD_NN_POS_JJ_IN_VBN_DT_:_NNS_VB_TO_-NONE-_VBZ_VBP    4.268093e+08  \n",
        "VBD_NN_POS_JJ_IN_._VBN_DT_:_VB_TO_-NONE-_VBZ_VBP      4.268096e+08  \n",
        "VBD_NN_POS_JJ_IN_._VBN_DT_:_NNS_VB_TO_-NONE-_VBZ_VBP  4.268093e+08  \n"
       ]
      }
     ],
     "prompt_number": 259
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Stemming"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "porter = PorterStemmer()\n",
      "porter.stem(\"presumably\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "u'presum'"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verbs = ['appears', 'appear', 'appeared', 'appearing', 'appearance']\n",
      "map(porter.stem, verbs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "[u'appear', u'appear', u'appear', u'appear', u'appear']"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence = \"Stemming is funnier than a bummer says the sushi loving computer scientist\"\n",
      "\" \".join(PorterStemmer().stem_word(word) for word in sentence.split(\" \"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "u'Stem is funnier than a bummer say the sushi love comput scientist'"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}